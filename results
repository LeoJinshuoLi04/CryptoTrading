=== Training LSTM model with Bitcoin feature: None ===
Label counts before split:
  -1: 495925
   0: 724699
   1: 484597
Training samples: 1364176, Testing samples: 341045
Training label distribution: Counter({np.int64(0): 575346, np.int64(-1): 399420, np.int64(1): 389410})
Testing label distribution: Counter({np.int64(0): 149353, np.int64(-1): 96505, np.int64(1): 95187})
Training LSTM model...
Epoch 1/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 135s 6ms/step - accuracy: 0.4505 - loss: 1.0498     
Epoch 2/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 122s 6ms/step - accuracy: 0.4664 - loss: 1.0298 
Epoch 3/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 128s 6ms/step - accuracy: 0.4722 - loss: 1.0232 
Epoch 4/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 129s 6ms/step - accuracy: 0.4775 - loss: 1.0175 
Epoch 5/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 132s 6ms/step - accuracy: 0.4820 - loss: 1.0110 
Epoch 6/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 133s 6ms/step - accuracy: 0.4856 - loss: 1.0067 
Epoch 7/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 139s 7ms/step - accuracy: 0.4875 - loss: 1.0028 
Epoch 8/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 131s 6ms/step - accuracy: 0.4911 - loss: 0.9992 
Epoch 9/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 136s 6ms/step - accuracy: 0.4933 - loss: 0.9967 
Epoch 10/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 141s 7ms/step - accuracy: 0.4955 - loss: 0.9931 
Epoch 11/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 140s 7ms/step - accuracy: 0.4967 - loss: 0.9914 
Epoch 12/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 141s 7ms/step - accuracy: 0.4974 - loss: 0.9898  
Epoch 13/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 140s 7ms/step - accuracy: 0.4999 - loss: 0.9875 
Epoch 14/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 139s 7ms/step - accuracy: 0.4996 - loss: 0.9866 
Epoch 15/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 141s 7ms/step - accuracy: 0.5012 - loss: 0.9844 
Epoch 16/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 129s 6ms/step - accuracy: 0.5012 - loss: 0.9845 
Epoch 17/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 126s 6ms/step - accuracy: 0.5021 - loss: 0.9830 
Epoch 18/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 120s 6ms/step - accuracy: 0.5022 - loss: 0.9824 
Epoch 19/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 125s 6ms/step - accuracy: 0.5034 - loss: 0.9817 
Epoch 20/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 128s 6ms/step - accuracy: 0.5035 - loss: 0.9802 
Epoch 21/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 123s 6ms/step - accuracy: 0.5050 - loss: 0.9792 
Epoch 22/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 124s 6ms/step - accuracy: 0.5058 - loss: 0.9782 
Epoch 23/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 124s 6ms/step - accuracy: 0.5055 - loss: 0.9775 
Epoch 24/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 126s 6ms/step - accuracy: 0.5058 - loss: 0.9775 
Epoch 25/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 134s 6ms/step - accuracy: 0.5064 - loss: 0.9769 
Epoch 26/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 129s 6ms/step - accuracy: 0.5061 - loss: 0.9768 
Epoch 27/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 125s 6ms/step - accuracy: 0.5071 - loss: 0.9757 
Epoch 28/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 127s 6ms/step - accuracy: 0.5076 - loss: 0.9752 
Epoch 29/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 133s 6ms/step - accuracy: 0.5074 - loss: 0.9749 
Epoch 30/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 125s 6ms/step - accuracy: 0.5074 - loss: 0.9748 
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
Saved trained model to models/model_no_btc.h5
Testing LSTM model...
Accuracy: 0.5227
Classification report:
              precision    recall  f1-score   support

          -1       0.45      0.43      0.44     96505
           0       0.55      0.78      0.65    149353
           1       0.54      0.22      0.31     95187

    accuracy                           0.52    341045
   macro avg       0.51      0.47      0.46    341045
weighted avg       0.52      0.52      0.49    341045


Dummy classifier baseline:
Dummy Accuracy: 0.3470
              precision    recall  f1-score   support

          -1       0.28      0.29      0.29     96505
           0       0.44      0.42      0.43    149353
           1       0.28      0.29      0.28     95187

    accuracy                           0.35    341045
   macro avg       0.33      0.33      0.33    341045
weighted avg       0.35      0.35      0.35    341045


=== Training LSTM model with Bitcoin feature: AdrActCnt ===
Combined DataFrame preview with Bitcoin feature 'AdrActCnt':
Label counts before split:
  -1: 495925
   0: 724699
   1: 484597
Training samples: 1364176, Testing samples: 341045
Training label distribution: Counter({np.int64(0): 575346, np.int64(-1): 399420, np.int64(1): 389410})
Testing label distribution: Counter({np.int64(0): 149353, np.int64(-1): 96505, np.int64(1): 95187})
Training LSTM model...
Epoch 1/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 135s 6ms/step - accuracy: 0.4523 - loss: 1.0477     
Epoch 2/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 134s 6ms/step - accuracy: 0.4709 - loss: 1.0256 
Epoch 3/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 126s 6ms/step - accuracy: 0.4800 - loss: 1.0153 
Epoch 4/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 126s 6ms/step - accuracy: 0.4874 - loss: 1.0067 
Epoch 5/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 130s 6ms/step - accuracy: 0.4934 - loss: 0.9994 
Epoch 6/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 127s 6ms/step - accuracy: 0.4986 - loss: 0.9927 
Epoch 7/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 130s 6ms/step - accuracy: 0.5032 - loss: 0.9857 
Epoch 8/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 127s 6ms/step - accuracy: 0.5074 - loss: 0.9806 
Epoch 9/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 128s 6ms/step - accuracy: 0.5101 - loss: 0.9765 
Epoch 10/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 127s 6ms/step - accuracy: 0.5126 - loss: 0.9726 
Epoch 11/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 132s 6ms/step - accuracy: 0.5155 - loss: 0.9691 
Epoch 12/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 131s 6ms/step - accuracy: 0.5184 - loss: 0.9660 
Epoch 13/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 127s 6ms/step - accuracy: 0.5193 - loss: 0.9634 
Epoch 14/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 125s 6ms/step - accuracy: 0.5212 - loss: 0.9604 
Epoch 15/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 130s 6ms/step - accuracy: 0.5227 - loss: 0.9582 
Epoch 16/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 134s 6ms/step - accuracy: 0.5252 - loss: 0.9554 
Epoch 17/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 124s 6ms/step - accuracy: 0.5266 - loss: 0.9537 
Epoch 18/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 125s 6ms/step - accuracy: 0.5282 - loss: 0.9514 
Epoch 19/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 133s 6ms/step - accuracy: 0.5298 - loss: 0.9499 
Epoch 20/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 125s 6ms/step - accuracy: 0.5311 - loss: 0.9474 
Epoch 21/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 130s 6ms/step - accuracy: 0.5320 - loss: 0.9465 
Epoch 22/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 127s 6ms/step - accuracy: 0.5348 - loss: 0.9436 
Epoch 23/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 124s 6ms/step - accuracy: 0.5344 - loss: 0.9428 
Epoch 24/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 126s 6ms/step - accuracy: 0.5360 - loss: 0.9407 
Epoch 25/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 130s 6ms/step - accuracy: 0.5368 - loss: 0.9397 
Epoch 26/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 128s 6ms/step - accuracy: 0.5380 - loss: 0.9383 
Epoch 27/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 131s 6ms/step - accuracy: 0.5376 - loss: 0.9378 
Epoch 28/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 126s 6ms/step - accuracy: 0.5395 - loss: 0.9360 
Epoch 29/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 128s 6ms/step - accuracy: 0.5392 - loss: 0.9354 
Epoch 30/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 130s 6ms/step - accuracy: 0.5399 - loss: 0.9350 
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
Saved trained model to models/model_AdrActCnt.h5
Testing LSTM model...
Accuracy: 0.5580
Classification report:
              precision    recall  f1-score   support

          -1       0.53      0.45      0.49     96505
           0       0.57      0.77      0.66    149353
           1       0.54      0.34      0.42     95187

    accuracy                           0.56    341045
   macro avg       0.55      0.52      0.52    341045
weighted avg       0.55      0.56      0.54    341045


Dummy classifier baseline:
Dummy Accuracy: 0.3470
              precision    recall  f1-score   support

          -1       0.28      0.29      0.29     96505
           0       0.44      0.42      0.43    149353
           1       0.28      0.29      0.28     95187

    accuracy                           0.35    341045
   macro avg       0.33      0.33      0.33    341045
weighted avg       0.35      0.35      0.35    341045


=== Training LSTM model with Bitcoin feature: TxVal ===
Combined DataFrame preview with Bitcoin feature 'TxVal':
Label counts before split:
  -1: 495925
   0: 724699
   1: 484597
Training samples: 1364176, Testing samples: 341045
Training label distribution: Counter({np.int64(0): 575346, np.int64(-1): 399420, np.int64(1): 389410})
Testing label distribution: Counter({np.int64(0): 149353, np.int64(-1): 96505, np.int64(1): 95187})
Training LSTM model...
Epoch 1/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 156s 7ms/step - accuracy: 0.4511 - loss: 1.0489     
Epoch 2/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 125s 6ms/step - accuracy: 0.4663 - loss: 1.0277 
Epoch 3/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 137s 6ms/step - accuracy: 0.4758 - loss: 1.0175 
Epoch 4/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 130s 6ms/step - accuracy: 0.4835 - loss: 1.0087 
Epoch 5/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 138s 6ms/step - accuracy: 0.4915 - loss: 0.9997 
Epoch 6/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 133s 6ms/step - accuracy: 0.4965 - loss: 0.9928 
Epoch 7/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 123s 6ms/step - accuracy: 0.5013 - loss: 0.9867 
Epoch 8/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 135s 6ms/step - accuracy: 0.5061 - loss: 0.9815 
Epoch 9/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 137s 6ms/step - accuracy: 0.5093 - loss: 0.9764 
Epoch 10/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 131s 6ms/step - accuracy: 0.5127 - loss: 0.9719 
Epoch 11/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 131s 6ms/step - accuracy: 0.5156 - loss: 0.9681 
Epoch 12/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 120s 6ms/step - accuracy: 0.5172 - loss: 0.9655 
Epoch 13/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 124s 6ms/step - accuracy: 0.5204 - loss: 0.9621 
Epoch 14/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 122s 6ms/step - accuracy: 0.5219 - loss: 0.9597 
Epoch 15/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 122s 6ms/step - accuracy: 0.5221 - loss: 0.9582 
Epoch 16/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 121s 6ms/step - accuracy: 0.5239 - loss: 0.9560 
Epoch 17/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 118s 6ms/step - accuracy: 0.5254 - loss: 0.9543 
Epoch 18/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 112s 5ms/step - accuracy: 0.5261 - loss: 0.9528 
Epoch 19/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 118s 6ms/step - accuracy: 0.5280 - loss: 0.9506 
Epoch 20/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 121s 6ms/step - accuracy: 0.5279 - loss: 0.9502 
Epoch 21/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.5290 - loss: 0.9479 
Epoch 22/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 125s 6ms/step - accuracy: 0.5303 - loss: 0.9467 
Epoch 23/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 119s 6ms/step - accuracy: 0.5306 - loss: 0.9457 
Epoch 24/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 118s 6ms/step - accuracy: 0.5320 - loss: 0.9433 
Epoch 25/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 120s 6ms/step - accuracy: 0.5333 - loss: 0.9429 
Epoch 26/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 123s 6ms/step - accuracy: 0.5337 - loss: 0.9416 
Epoch 27/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 123s 6ms/step - accuracy: 0.5335 - loss: 0.9419 
Epoch 28/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 121s 6ms/step - accuracy: 0.5343 - loss: 0.9404 
Epoch 29/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 121s 6ms/step - accuracy: 0.5357 - loss: 0.9390 
Epoch 30/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 120s 6ms/step - accuracy: 0.5365 - loss: 0.9384 
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
Saved trained model to models/model_TxVal.h5
Testing LSTM model...
Accuracy: 0.5508
Classification report:
              precision    recall  f1-score   support

          -1       0.50      0.50      0.50     96505
           0       0.58      0.75      0.65    149353
           1       0.55      0.29      0.38     95187

    accuracy                           0.55    341045
   macro avg       0.54      0.51      0.51    341045
weighted avg       0.55      0.55      0.53    341045


Dummy classifier baseline:
Dummy Accuracy: 0.3470
              precision    recall  f1-score   support

          -1       0.28      0.29      0.29     96505
           0       0.44      0.42      0.43    149353
           1       0.28      0.29      0.28     95187

    accuracy                           0.35    341045
   macro avg       0.33      0.33      0.33    341045
weighted avg       0.35      0.35      0.35    341045


=== Training LSTM model with Bitcoin feature: TxCnt ===
Combined DataFrame preview with Bitcoin feature 'TxCnt':
Label counts before split:
  -1: 495925
   0: 724699
   1: 484597
Training samples: 1364176, Testing samples: 341045
Training label distribution: Counter({np.int64(0): 575346, np.int64(-1): 399420, np.int64(1): 389410})
Testing label distribution: Counter({np.int64(0): 149353, np.int64(-1): 96505, np.int64(1): 95187})
Training LSTM model...
Epoch 1/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 131s 6ms/step - accuracy: 0.4513 - loss: 1.0485     
Epoch 2/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 118s 6ms/step - accuracy: 0.4716 - loss: 1.0241 
Epoch 3/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 112s 5ms/step - accuracy: 0.4809 - loss: 1.0134 
Epoch 4/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 120s 6ms/step - accuracy: 0.4881 - loss: 1.0046 
Epoch 5/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 113s 5ms/step - accuracy: 0.4944 - loss: 0.9969 
Epoch 6/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 119s 6ms/step - accuracy: 0.4994 - loss: 0.9901 
Epoch 7/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 127s 6ms/step - accuracy: 0.5037 - loss: 0.9840 
Epoch 8/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 114s 5ms/step - accuracy: 0.5075 - loss: 0.9784 
Epoch 9/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.5111 - loss: 0.9736 
Epoch 10/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 119s 6ms/step - accuracy: 0.5139 - loss: 0.9702 
Epoch 11/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5159 - loss: 0.9657 
Epoch 12/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 119s 6ms/step - accuracy: 0.5183 - loss: 0.9630 
Epoch 13/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 118s 6ms/step - accuracy: 0.5202 - loss: 0.9599 
Epoch 14/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 118s 6ms/step - accuracy: 0.5222 - loss: 0.9577 
Epoch 15/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 118s 6ms/step - accuracy: 0.5233 - loss: 0.9555 
Epoch 16/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 120s 6ms/step - accuracy: 0.5255 - loss: 0.9526 
Epoch 17/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 118s 6ms/step - accuracy: 0.5268 - loss: 0.9511 
Epoch 18/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.5276 - loss: 0.9499 
Epoch 19/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 118s 6ms/step - accuracy: 0.5298 - loss: 0.9469 
Epoch 20/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5305 - loss: 0.9463 
Epoch 21/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 112s 5ms/step - accuracy: 0.5322 - loss: 0.9437 
Epoch 22/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 111s 5ms/step - accuracy: 0.5330 - loss: 0.9423  
Epoch 23/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 111s 5ms/step - accuracy: 0.5337 - loss: 0.9410 
Epoch 24/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 113s 5ms/step - accuracy: 0.5354 - loss: 0.9400 
Epoch 25/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 112s 5ms/step - accuracy: 0.5359 - loss: 0.9385 
Epoch 26/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 109s 5ms/step - accuracy: 0.5366 - loss: 0.9382 
Epoch 27/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 119s 6ms/step - accuracy: 0.5368 - loss: 0.9367 
Epoch 28/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 113s 5ms/step - accuracy: 0.5388 - loss: 0.9351 
Epoch 29/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 113s 5ms/step - accuracy: 0.5384 - loss: 0.9349 
Epoch 30/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 109s 5ms/step - accuracy: 0.5390 - loss: 0.9338 
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
Saved trained model to models/model_TxCnt.h5
Testing LSTM model...
Accuracy: 0.5539
Classification report:
              precision    recall  f1-score   support

          -1       0.51      0.48      0.50     96505
           0       0.57      0.76      0.65    149353
           1       0.55      0.31      0.40     95187

    accuracy                           0.55    341045
   macro avg       0.55      0.52      0.51    341045
weighted avg       0.55      0.55      0.54    341045


Dummy classifier baseline:
Dummy Accuracy: 0.3470
              precision    recall  f1-score   support

          -1       0.28      0.29      0.29     96505
           0       0.44      0.42      0.43    149353
           1       0.28      0.29      0.28     95187

    accuracy                           0.35    341045
   macro avg       0.33      0.33      0.33    341045
weighted avg       0.35      0.35      0.35    341045


=== Training LSTM model with Bitcoin feature: FeeMean ===
Combined DataFrame preview with Bitcoin feature 'FeeMean':
Label counts before split:
  -1: 495925
   0: 724699
   1: 484597
Training samples: 1364176, Testing samples: 341045
Training label distribution: Counter({np.int64(0): 575346, np.int64(-1): 399420, np.int64(1): 389410})
Testing label distribution: Counter({np.int64(0): 149353, np.int64(-1): 96505, np.int64(1): 95187})
Training LSTM model...
Epoch 1/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 118s 5ms/step - accuracy: 0.4521 - loss: 1.0482     
Epoch 2/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.4675 - loss: 1.0281  
Epoch 3/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.4745 - loss: 1.0211 
Epoch 4/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 118s 6ms/step - accuracy: 0.4800 - loss: 1.0150 
Epoch 5/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.4835 - loss: 1.0095 
Epoch 6/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 112s 5ms/step - accuracy: 0.4868 - loss: 1.0050 
Epoch 7/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 110s 5ms/step - accuracy: 0.4900 - loss: 1.0012 
Epoch 8/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.4934 - loss: 0.9966 
Epoch 9/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 113s 5ms/step - accuracy: 0.4955 - loss: 0.9939 
Epoch 10/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 114s 5ms/step - accuracy: 0.4970 - loss: 0.9918 
Epoch 11/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 113s 5ms/step - accuracy: 0.4991 - loss: 0.9889 
Epoch 12/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 111s 5ms/step - accuracy: 0.4993 - loss: 0.9877 
Epoch 13/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5008 - loss: 0.9859 
Epoch 14/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 111s 5ms/step - accuracy: 0.5024 - loss: 0.9842 
Epoch 15/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5032 - loss: 0.9825 
Epoch 16/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 112s 5ms/step - accuracy: 0.5039 - loss: 0.9820 
Epoch 17/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 111s 5ms/step - accuracy: 0.5046 - loss: 0.9803 
Epoch 18/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 113s 5ms/step - accuracy: 0.5053 - loss: 0.9798 
Epoch 19/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 112s 5ms/step - accuracy: 0.5053 - loss: 0.9796 
Epoch 20/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 109s 5ms/step - accuracy: 0.5056 - loss: 0.9787 
Epoch 21/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 111s 5ms/step - accuracy: 0.5062 - loss: 0.9776 
Epoch 22/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5067 - loss: 0.9771 
Epoch 23/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 112s 5ms/step - accuracy: 0.5079 - loss: 0.9762 
Epoch 24/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 112s 5ms/step - accuracy: 0.5075 - loss: 0.9757 
Epoch 25/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 113s 5ms/step - accuracy: 0.5083 - loss: 0.9752 
Epoch 26/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.5090 - loss: 0.9742  
Epoch 27/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 112s 5ms/step - accuracy: 0.5095 - loss: 0.9735 
Epoch 28/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5093 - loss: 0.9737 
Epoch 29/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5096 - loss: 0.9731 
Epoch 30/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 114s 5ms/step - accuracy: 0.5106 - loss: 0.9722 
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
Saved trained model to models/model_FeeMean.h5
Testing LSTM model...
Accuracy: 0.5269
Classification report:
              precision    recall  f1-score   support

          -1       0.46      0.41      0.44     96505
           0       0.56      0.78      0.65    149353
           1       0.51      0.25      0.34     95187

    accuracy                           0.53    341045
   macro avg       0.51      0.48      0.47    341045
weighted avg       0.52      0.53      0.50    341045


Dummy classifier baseline:
Dummy Accuracy: 0.3470
              precision    recall  f1-score   support

          -1       0.28      0.29      0.29     96505
           0       0.44      0.42      0.43    149353
           1       0.28      0.29      0.28     95187

    accuracy                           0.35    341045
   macro avg       0.33      0.33      0.33    341045
weighted avg       0.35      0.35      0.35    341045


=== Training LSTM model with Bitcoin feature: HashRate ===
Combined DataFrame preview with Bitcoin feature 'HashRate':
Label counts before split:
  -1: 495925
   0: 724699
   1: 484597
Training samples: 1364176, Testing samples: 341045
Training label distribution: Counter({np.int64(0): 575346, np.int64(-1): 399420, np.int64(1): 389410})
Testing label distribution: Counter({np.int64(0): 149353, np.int64(-1): 96505, np.int64(1): 95187})
Training LSTM model...
Epoch 1/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 122s 6ms/step - accuracy: 0.4517 - loss: 1.0484     
Epoch 2/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 121s 6ms/step - accuracy: 0.4679 - loss: 1.0267 
Epoch 3/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 123s 6ms/step - accuracy: 0.4763 - loss: 1.0180 
Epoch 4/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 120s 6ms/step - accuracy: 0.4812 - loss: 1.0100 
Epoch 5/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 121s 6ms/step - accuracy: 0.4846 - loss: 1.0053 
Epoch 6/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.4880 - loss: 1.0003 
Epoch 7/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 125s 6ms/step - accuracy: 0.4934 - loss: 0.9947 
Epoch 8/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 124s 6ms/step - accuracy: 0.4951 - loss: 0.9920 
Epoch 9/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 119s 6ms/step - accuracy: 0.4976 - loss: 0.9890 
Epoch 10/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 119s 6ms/step - accuracy: 0.5001 - loss: 0.9858 
Epoch 11/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 119s 6ms/step - accuracy: 0.5000 - loss: 0.9845 
Epoch 12/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 120s 6ms/step - accuracy: 0.5034 - loss: 0.9811 
Epoch 13/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5049 - loss: 0.9788 
Epoch 14/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 6ms/step - accuracy: 0.5048 - loss: 0.9778 
Epoch 15/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 124s 6ms/step - accuracy: 0.5062 - loss: 0.9761 
Epoch 16/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 113s 5ms/step - accuracy: 0.5075 - loss: 0.9749  
Epoch 17/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.5089 - loss: 0.9732 
Epoch 18/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.5097 - loss: 0.9720 
Epoch 19/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5107 - loss: 0.9707 
Epoch 20/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 113s 5ms/step - accuracy: 0.5113 - loss: 0.9693 
Epoch 21/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 119s 6ms/step - accuracy: 0.5125 - loss: 0.9678 
Epoch 22/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5136 - loss: 0.9662 
Epoch 23/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.5135 - loss: 0.9664 
Epoch 24/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 114s 5ms/step - accuracy: 0.5142 - loss: 0.9645 
Epoch 25/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.5146 - loss: 0.9638 
Epoch 26/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.5156 - loss: 0.9624 
Epoch 27/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.5156 - loss: 0.9625 
Epoch 28/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.5165 - loss: 0.9620 
Epoch 29/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.5169 - loss: 0.9611 
Epoch 30/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 114s 5ms/step - accuracy: 0.5184 - loss: 0.9599 
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
Saved trained model to models/model_HashRate.h5
Testing LSTM model...
Accuracy: 0.5339
Classification report:
              precision    recall  f1-score   support

          -1       0.47      0.46      0.46     96505
           0       0.57      0.76      0.65    149353
           1       0.53      0.25      0.34     95187

    accuracy                           0.53    341045
   macro avg       0.52      0.49      0.48    341045
weighted avg       0.53      0.53      0.51    341045


Dummy classifier baseline:
Dummy Accuracy: 0.3470
              precision    recall  f1-score   support

          -1       0.28      0.29      0.29     96505
           0       0.44      0.42      0.43    149353
           1       0.28      0.29      0.28     95187

    accuracy                           0.35    341045
   macro avg       0.33      0.33      0.33    341045
weighted avg       0.35      0.35      0.35    341045


=== Training LSTM model with Bitcoin feature: GoogleTrends ===
Combined DataFrame preview with Bitcoin feature 'GoogleTrends':
Label counts before split:
  -1: 495925
   0: 724699
   1: 484597
Training samples: 1364176, Testing samples: 341045
Training label distribution: Counter({np.int64(0): 575346, np.int64(-1): 399420, np.int64(1): 389410})
Testing label distribution: Counter({np.int64(0): 149353, np.int64(-1): 96505, np.int64(1): 95187})
Training LSTM model...
Epoch 1/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 131s 6ms/step - accuracy: 0.4507 - loss: 1.0490     
Epoch 2/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 134s 6ms/step - accuracy: 0.4677 - loss: 1.0268 
Epoch 3/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 129s 6ms/step - accuracy: 0.4782 - loss: 1.0165 
Epoch 4/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 123s 6ms/step - accuracy: 0.4873 - loss: 1.0054 
Epoch 5/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 127s 6ms/step - accuracy: 0.4960 - loss: 0.9945 
Epoch 6/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 125s 6ms/step - accuracy: 0.5009 - loss: 0.9870 
Epoch 7/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 130s 6ms/step - accuracy: 0.5061 - loss: 0.9800 
Epoch 8/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 130s 6ms/step - accuracy: 0.5093 - loss: 0.9755 
Epoch 9/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 122s 6ms/step - accuracy: 0.5116 - loss: 0.9722 
Epoch 10/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 122s 6ms/step - accuracy: 0.5151 - loss: 0.9679 
Epoch 11/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 114s 5ms/step - accuracy: 0.5160 - loss: 0.9662 
Epoch 12/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 114s 5ms/step - accuracy: 0.5181 - loss: 0.9635 
Epoch 13/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5191 - loss: 0.9614 
Epoch 14/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.5206 - loss: 0.9589 
Epoch 15/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 112s 5ms/step - accuracy: 0.5203 - loss: 0.9590 
Epoch 16/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.5230 - loss: 0.9566 
Epoch 17/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.5239 - loss: 0.9547 
Epoch 18/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.5247 - loss: 0.9533 
Epoch 19/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5265 - loss: 0.9515  
Epoch 20/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.5270 - loss: 0.9505 
Epoch 21/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.5286 - loss: 0.9488 
Epoch 22/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.5281 - loss: 0.9485 
Epoch 23/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 111s 5ms/step - accuracy: 0.5289 - loss: 0.9473 
Epoch 24/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 6ms/step - accuracy: 0.5308 - loss: 0.9456 
Epoch 25/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 111s 5ms/step - accuracy: 0.5310 - loss: 0.9454 
Epoch 26/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 116s 5ms/step - accuracy: 0.5313 - loss: 0.9444 
Epoch 27/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 113s 5ms/step - accuracy: 0.5317 - loss: 0.9434 
Epoch 28/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 115s 5ms/step - accuracy: 0.5324 - loss: 0.9426 
Epoch 29/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 117s 5ms/step - accuracy: 0.5331 - loss: 0.9417 
Epoch 30/30
21316/21316 ━━━━━━━━━━━━━━━━━━━━ 119s 6ms/step - accuracy: 0.5335 - loss: 0.9410 
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
Saved trained model to models/model_GoogleTrends.h5
Testing LSTM model...
Accuracy: 0.5502
Classification report:
              precision    recall  f1-score   support

          -1       0.50      0.48      0.49     96505
           0       0.57      0.76      0.65    149353
           1       0.57      0.29      0.38     95187

    accuracy                           0.55    341045
   macro avg       0.54      0.51      0.51    341045
weighted avg       0.55      0.55      0.53    341045


Dummy classifier baseline:
Dummy Accuracy: 0.3470
              precision    recall  f1-score   support

          -1       0.28      0.29      0.29     96505
           0       0.44      0.42      0.43    149353
           1       0.28      0.29      0.28     95187

    accuracy                           0.35    341045
   macro avg       0.33      0.33      0.33    341045
weighted avg       0.35      0.35      0.35    341045


All models processed.